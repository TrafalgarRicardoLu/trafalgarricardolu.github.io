<!DOCTYPE html>
<html>
<head>

    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- Base Meta -->
    <!-- dynamically fixing the title for tag/author pages -->



    <title>浅谈Memcache</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.edited.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />
    <!-- highlight.js -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>

    <!--[if IE]>
        <style>
            p, ol, ul{
                width: 100%;
            }
            blockquote{
                width: 100%;
            }
        </style>
    <![endif]-->
    
    <!-- This tag outputs SEO meta+structured data and other important settings -->
    <meta name="description" content="The professional publishing platform" />
    <link rel="shortcut icon" href="http://localhost:4000/assets/images/favicon.png" type="image/png" />
    <link rel="canonical" href="http://localhost:4000/%E6%B5%85%E8%B0%88Memcache" />
    <meta name="referrer" content="no-referrer-when-downgrade" />

     <!--title below is coming from _includes/dynamic_title-->
    <meta property="og:site_name" content="Ghost" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="浅谈Memcache" />
    <meta property="og:description" content="上图为Facebook登录页面图片 Facebook拥有庞大的社交网络和因此产生的频繁的请求，所以为了提高响应速度，使用了缓存的策略处理这一问题。通常情况下，用户的读写请求都会落到数据库上，而数据库的数据存储在磁盘上，磁盘低下的读写效率对响应的速度影响很大。所以，Facebook使用运行在内存中的Memcached作为中间件，先在其中查询相关数据，只有当Memcached中没有请求的数据时才向数据库查询。他们充分利用了内存远高于磁盘的读写速度，实现了业务的优化。下面，我会根据其论文谈谈他们具体是怎么做的。要特别指出的是，Memcache指的的整个系统，而Memcached则是服务器中的组件，众多Memcached服务器组成了Memcache系统，两者是不同的。 总体架构 Memcache的总体架构如下图所示 类似于Aurora和Spanner，Facebook也有Region的概念。现在，我们可以基本确定，Region指的是物理上实现地理分割的不同数据中心，这样划分可以根据用户的地理位置选择最近的数据中心来减少延迟。不同的Region之间只同步存储的数据。每个Region中有多个Cluster（集群），每个Cluster中又有多个Web服务器和Memcache系统，但每个Region只有唯一的存储集群。在这里，我想每个Cluster负责的业务应该是不同的，而每个Cluster中的多个服务器则应该是被用于实现均衡负载。 另外要讲的是Memcache的读写模型。Memcache使用的是Look-aside策略：服务器先尝试向Memcache读取数据，如果没有数据，则服务器再向数据库读取数据，读取完毕后将Memcache中的数据更新。示意图如下： 与之对应的是Inline策略，服务器尝试向Cache读取数据失败后，由Cache而不是服务器去数据库读取数据，再从Cache返回数据给服务器。 两者的区别在于处理数据缺失时的压力是由服务器还是缓存来承担。 下面，Memcache根据Cluster和Region分别讨论起内部的要求和优化。特别要说的是，在Facebook的应用场景中，读请求远比写请求多。 In Cluster 在Cluster中，Memcache主要关注两点，一是延迟（Latency），二是负载（Load）。 Latency 在Facebook的服务中，一次get请求不仅仅只读取单个K-V对，根据统计，一次页面的加载平均要从Memcache读取521个不同的数据，所以必须要采取一些措施来降低读取数据的延迟。 第一，Memcache使用DAG来表示数据直接的依赖关系。如果有两组完全不相关的数据，那么这两组数据就可以并行地读取，而单个DAG中的数据可以一次性提交读请求而不是每个数据提交一次。这里使用的并行和批读取数据有效地提升了读取速度。 第二，Memcache使用UDP来发送读请求，TPC处理Set和Delete请求。由于UDP只负责发送而不考虑可靠性，也不维护链接，所以UDP要比TCP快。在大多数为读请求的情况下，使用UDP而不是TCP能减少读取的时间。而Set和Delete请求则要求必须可达，所以使用TCP。下图展示了UDP和TCP的性能比较。 第三，Memcache自己实现了一个类似TCP的拥塞窗口控制的机制以防止出现热点或阻塞。因为使用UDP传输读请求，所以自然也就没有TCP的拥塞窗口控制了。那么一旦出现大量的请求，UDP可能会使请求阻塞或者直接抛弃请求，抛弃请求则会使客户端重新发起请求，这两者都会影响整体的响应时间。所以Memcache在上层又实现了滑动窗口机制。 Load 在Look-aside模型中，当数据不再Memcache中时，会向数据库读取数据，在这种情况下，会出现很多情况，从而导致负载加重。Memcache使用下列方法减少负载。 第一，Memcache使用Lease处理两个问题：Stale Set和Thundering Herd。Stale Set指的是服务器在Memcache中设置了过期的数据，这个数据不能反映最新的值。Thundering Herd指的是某个值在一段时间内被大量地读和写，如果Memcache中存的数据不是最新的，读和写就要去请求数据库，这导致数据库的负载大幅增加。 为了解决Stale Set问题，在Cache 未命中的时候，Memcache会给客户端分配一个64位的Lease， 当拿到数据库数据之后，需要使用这个Lease来证明其身份。如果这个数据在返回之前被Delete或者更改了，也就是说，现在的数据是更新的，那么这个Lease就会被认为是无效的，从而拒绝旧的写入。 为了解决Thunder Herd问题，Memcache会每10秒钟给这大量请求中的一个请求分配Lease，其他的客户端则被要求等待。这个持有Lease的请求会继续其流程，访问数据库，更新Memcache中的数据。而当Memcache中的数据被更新后，其他客户端会重新发起请求，这时大多数就能拿到其想要的数据了。那么，在整个流程中，重复的查询和写入被减少为一次。论文中表示，Lease的引入将数据库的查询次数从17K/S降低到了1.3K/S。 第二，Memcache使用了Memcache Pool来分别处理不同场景的数据。论文中举了例子说，可以为经常访问但处理Cache未命中的开销不大的Key提供一个小的Pool 。可以为不经常访问的Key提供一个大型Pool ，因为对于这些Key来说，Cache未命中的代价很高。 另外，论文还讨论了应该使用分片还是复制降低负载。考虑系统总共每秒1M个请求，一次客户端发起的请求包含100个key。如果是使用分片的话，假设对应的数据平均分配在在两台机器上，100个Key的请求，每台机器存储的恰好是50个Key，那么两台每秒仍然要处理1M个请求，只是每个请求拿的key少了，这是存储问题，但是不能解决 QPS 过高。使用复制的话，那么每台机器就只需要处理0.5M个请求了。所以，Memcache最后使用复制实习均衡负载。 Handle Failure 在缓存系统中，我们仍然要考虑容错的问题。因为Memcache是缓存系统，所以不影响数据库本身的正确性，那么我们就无需考虑一致性的问题，只需要考虑均衡负载，把本应分配给崩溃机器的请求分配给其他机器。 Memcache将崩溃分为两种情况，很少一部分机器崩溃，很大一部分机器崩溃。 很少一部分机器崩溃的解决依赖自动修复系统，Memcache准备了约占总机器数1%的机器来接管崩溃机器的服务，这些备用机器被称为Gutter。一旦客户端发现请求没有回应，它们就认为该机器崩溃，然后将请求转发到Gutter服务区上。 很大一部分机器崩溃的话，Memcache会考虑将这个Cluster的请求转发到其他Cluster上，以保证服务能正常提供。 In Region 在这部分中，Memcache讨论了在同一Region中的一些问题。 Regional Invalidations 考虑一下，某个客户端的写入请求会使存储集群的数据发生变化，但是这里的变化没有经过其他Memcache或者其他客户端，所以Memcache中的缓存实际是过时的，但是其他客户端和其他Memcache都不能意识到这一点，所以必须由数据存储集群来处理这个问题。 Memcache通过设置守护程序McSqueal来解决这个问题。当更新内容被Commit后，其会被送入到McSqueal中，McSqueal会判断这条语句是否会影响数据一致性。如果发现可能影响一致性的操作，它会将相关的信息送入Mcrouter中，再由Mcrouter发送给Memcache，这样Memcache就能根据相关的信息更新本地的数据，以此实现数据的一致性。在这里，McSqueal还使用批处理来降低系统的负载。其示意图如下。" />
    <meta property="og:url" content="http://localhost:4000/%E6%B5%85%E8%B0%88Memcache" />
    <meta property="og:image" content="http://localhost:4000/assets/images/memcache.jpg" />
    <meta property="article:publisher" content="https://www.facebook.com/ghost" />
    <meta property="article:author" content="https://www.facebook.com/ghost" />
    <meta property="article:published_time" content="2020-08-24T19:00:00+08:00" />
    <meta property="article:modified_time" content="2020-08-24T19:00:00+08:00" />
    <meta property="article:tag" content="Distributedsystem" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="浅谈Memcache" />
    <meta name="twitter:description" content="上图为Facebook登录页面图片 Facebook拥有庞大的社交网络和因此产生的频繁的请求，所以为了提高响应速度，使用了缓存的策略处理这一问题。通常情况下，用户的读写请求都会落到数据库上，而数据库的数据存储在磁盘上，磁盘低下的读写效率对响应的速度影响很大。所以，Facebook使用运行在内存中的Memcached作为中间件，先在其中查询相关数据，只有当Memcached中没有请求的数据时才向数据库查询。他们充分利用了内存远高于磁盘的读写速度，实现了业务的优化。下面，我会根据其论文谈谈他们具体是怎么做的。要特别指出的是，Memcache指的的整个系统，而Memcached则是服务器中的组件，众多Memcached服务器组成了Memcache系统，两者是不同的。 总体架构 Memcache的总体架构如下图所示 类似于Aurora和Spanner，Facebook也有Region的概念。现在，我们可以基本确定，Region指的是物理上实现地理分割的不同数据中心，这样划分可以根据用户的地理位置选择最近的数据中心来减少延迟。不同的Region之间只同步存储的数据。每个Region中有多个Cluster（集群），每个Cluster中又有多个Web服务器和Memcache系统，但每个Region只有唯一的存储集群。在这里，我想每个Cluster负责的业务应该是不同的，而每个Cluster中的多个服务器则应该是被用于实现均衡负载。 另外要讲的是Memcache的读写模型。Memcache使用的是Look-aside策略：服务器先尝试向Memcache读取数据，如果没有数据，则服务器再向数据库读取数据，读取完毕后将Memcache中的数据更新。示意图如下： 与之对应的是Inline策略，服务器尝试向Cache读取数据失败后，由Cache而不是服务器去数据库读取数据，再从Cache返回数据给服务器。 两者的区别在于处理数据缺失时的压力是由服务器还是缓存来承担。 下面，Memcache根据Cluster和Region分别讨论起内部的要求和优化。特别要说的是，在Facebook的应用场景中，读请求远比写请求多。 In Cluster 在Cluster中，Memcache主要关注两点，一是延迟（Latency），二是负载（Load）。 Latency 在Facebook的服务中，一次get请求不仅仅只读取单个K-V对，根据统计，一次页面的加载平均要从Memcache读取521个不同的数据，所以必须要采取一些措施来降低读取数据的延迟。 第一，Memcache使用DAG来表示数据直接的依赖关系。如果有两组完全不相关的数据，那么这两组数据就可以并行地读取，而单个DAG中的数据可以一次性提交读请求而不是每个数据提交一次。这里使用的并行和批读取数据有效地提升了读取速度。 第二，Memcache使用UDP来发送读请求，TPC处理Set和Delete请求。由于UDP只负责发送而不考虑可靠性，也不维护链接，所以UDP要比TCP快。在大多数为读请求的情况下，使用UDP而不是TCP能减少读取的时间。而Set和Delete请求则要求必须可达，所以使用TCP。下图展示了UDP和TCP的性能比较。 第三，Memcache自己实现了一个类似TCP的拥塞窗口控制的机制以防止出现热点或阻塞。因为使用UDP传输读请求，所以自然也就没有TCP的拥塞窗口控制了。那么一旦出现大量的请求，UDP可能会使请求阻塞或者直接抛弃请求，抛弃请求则会使客户端重新发起请求，这两者都会影响整体的响应时间。所以Memcache在上层又实现了滑动窗口机制。 Load 在Look-aside模型中，当数据不再Memcache中时，会向数据库读取数据，在这种情况下，会出现很多情况，从而导致负载加重。Memcache使用下列方法减少负载。 第一，Memcache使用Lease处理两个问题：Stale Set和Thundering Herd。Stale Set指的是服务器在Memcache中设置了过期的数据，这个数据不能反映最新的值。Thundering Herd指的是某个值在一段时间内被大量地读和写，如果Memcache中存的数据不是最新的，读和写就要去请求数据库，这导致数据库的负载大幅增加。 为了解决Stale Set问题，在Cache 未命中的时候，Memcache会给客户端分配一个64位的Lease， 当拿到数据库数据之后，需要使用这个Lease来证明其身份。如果这个数据在返回之前被Delete或者更改了，也就是说，现在的数据是更新的，那么这个Lease就会被认为是无效的，从而拒绝旧的写入。 为了解决Thunder Herd问题，Memcache会每10秒钟给这大量请求中的一个请求分配Lease，其他的客户端则被要求等待。这个持有Lease的请求会继续其流程，访问数据库，更新Memcache中的数据。而当Memcache中的数据被更新后，其他客户端会重新发起请求，这时大多数就能拿到其想要的数据了。那么，在整个流程中，重复的查询和写入被减少为一次。论文中表示，Lease的引入将数据库的查询次数从17K/S降低到了1.3K/S。 第二，Memcache使用了Memcache Pool来分别处理不同场景的数据。论文中举了例子说，可以为经常访问但处理Cache未命中的开销不大的Key提供一个小的Pool 。可以为不经常访问的Key提供一个大型Pool ，因为对于这些Key来说，Cache未命中的代价很高。 另外，论文还讨论了应该使用分片还是复制降低负载。考虑系统总共每秒1M个请求，一次客户端发起的请求包含100个key。如果是使用分片的话，假设对应的数据平均分配在在两台机器上，100个Key的请求，每台机器存储的恰好是50个Key，那么两台每秒仍然要处理1M个请求，只是每个请求拿的key少了，这是存储问题，但是不能解决 QPS 过高。使用复制的话，那么每台机器就只需要处理0.5M个请求了。所以，Memcache最后使用复制实习均衡负载。 Handle Failure 在缓存系统中，我们仍然要考虑容错的问题。因为Memcache是缓存系统，所以不影响数据库本身的正确性，那么我们就无需考虑一致性的问题，只需要考虑均衡负载，把本应分配给崩溃机器的请求分配给其他机器。 Memcache将崩溃分为两种情况，很少一部分机器崩溃，很大一部分机器崩溃。 很少一部分机器崩溃的解决依赖自动修复系统，Memcache准备了约占总机器数1%的机器来接管崩溃机器的服务，这些备用机器被称为Gutter。一旦客户端发现请求没有回应，它们就认为该机器崩溃，然后将请求转发到Gutter服务区上。 很大一部分机器崩溃的话，Memcache会考虑将这个Cluster的请求转发到其他Cluster上，以保证服务能正常提供。 In Region 在这部分中，Memcache讨论了在同一Region中的一些问题。 Regional Invalidations 考虑一下，某个客户端的写入请求会使存储集群的数据发生变化，但是这里的变化没有经过其他Memcache或者其他客户端，所以Memcache中的缓存实际是过时的，但是其他客户端和其他Memcache都不能意识到这一点，所以必须由数据存储集群来处理这个问题。 Memcache通过设置守护程序McSqueal来解决这个问题。当更新内容被Commit后，其会被送入到McSqueal中，McSqueal会判断这条语句是否会影响数据一致性。如果发现可能影响一致性的操作，它会将相关的信息送入Mcrouter中，再由Mcrouter发送给Memcache，这样Memcache就能根据相关的信息更新本地的数据，以此实现数据的一致性。在这里，McSqueal还使用批处理来降低系统的负载。其示意图如下。" />
    <meta name="twitter:url" content="http://localhost:4000/" />
    <meta name="twitter:image" content="http://localhost:4000/assets/images/memcache.jpg" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Ghost" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="Distributedsystem" />
    <meta name="twitter:site" content="@tryghost" />
    <meta name="twitter:creator" content="@tryghost" />
    <meta property="og:image:width" content="1400" />
    <meta property="og:image:height" content="933" />

    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Website",
    "publisher": {
        "@type": "Organization",
        "name": "Ghost",
        "logo": "http://localhost:4000/assets/images/blog-icon.png"
    },
    "url": "http://localhost:4000/%E6%B5%85%E8%B0%88Memcache",
    "image": {
        "@type": "ImageObject",
        "url": "http://localhost:4000/assets/images/memcache.jpg",
        "width": 2000,
        "height": 666
    },
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://localhost:4000/%E6%B5%85%E8%B0%88Memcache"
    },
    "description": "上图为Facebook登录页面图片 Facebook拥有庞大的社交网络和因此产生的频繁的请求，所以为了提高响应速度，使用了缓存的策略处理这一问题。通常情况下，用户的读写请求都会落到数据库上，而数据库的数据存储在磁盘上，磁盘低下的读写效率对响应的速度影响很大。所以，Facebook使用运行在内存中的Memcached作为中间件，先在其中查询相关数据，只有当Memcached中没有请求的数据时才向数据库查询。他们充分利用了内存远高于磁盘的读写速度，实现了业务的优化。下面，我会根据其论文谈谈他们具体是怎么做的。要特别指出的是，Memcache指的的整个系统，而Memcached则是服务器中的组件，众多Memcached服务器组成了Memcache系统，两者是不同的。 总体架构 Memcache的总体架构如下图所示 类似于Aurora和Spanner，Facebook也有Region的概念。现在，我们可以基本确定，Region指的是物理上实现地理分割的不同数据中心，这样划分可以根据用户的地理位置选择最近的数据中心来减少延迟。不同的Region之间只同步存储的数据。每个Region中有多个Cluster（集群），每个Cluster中又有多个Web服务器和Memcache系统，但每个Region只有唯一的存储集群。在这里，我想每个Cluster负责的业务应该是不同的，而每个Cluster中的多个服务器则应该是被用于实现均衡负载。 另外要讲的是Memcache的读写模型。Memcache使用的是Look-aside策略：服务器先尝试向Memcache读取数据，如果没有数据，则服务器再向数据库读取数据，读取完毕后将Memcache中的数据更新。示意图如下： 与之对应的是Inline策略，服务器尝试向Cache读取数据失败后，由Cache而不是服务器去数据库读取数据，再从Cache返回数据给服务器。 两者的区别在于处理数据缺失时的压力是由服务器还是缓存来承担。 下面，Memcache根据Cluster和Region分别讨论起内部的要求和优化。特别要说的是，在Facebook的应用场景中，读请求远比写请求多。 In Cluster 在Cluster中，Memcache主要关注两点，一是延迟（Latency），二是负载（Load）。 Latency 在Facebook的服务中，一次get请求不仅仅只读取单个K-V对，根据统计，一次页面的加载平均要从Memcache读取521个不同的数据，所以必须要采取一些措施来降低读取数据的延迟。 第一，Memcache使用DAG来表示数据直接的依赖关系。如果有两组完全不相关的数据，那么这两组数据就可以并行地读取，而单个DAG中的数据可以一次性提交读请求而不是每个数据提交一次。这里使用的并行和批读取数据有效地提升了读取速度。 第二，Memcache使用UDP来发送读请求，TPC处理Set和Delete请求。由于UDP只负责发送而不考虑可靠性，也不维护链接，所以UDP要比TCP快。在大多数为读请求的情况下，使用UDP而不是TCP能减少读取的时间。而Set和Delete请求则要求必须可达，所以使用TCP。下图展示了UDP和TCP的性能比较。 第三，Memcache自己实现了一个类似TCP的拥塞窗口控制的机制以防止出现热点或阻塞。因为使用UDP传输读请求，所以自然也就没有TCP的拥塞窗口控制了。那么一旦出现大量的请求，UDP可能会使请求阻塞或者直接抛弃请求，抛弃请求则会使客户端重新发起请求，这两者都会影响整体的响应时间。所以Memcache在上层又实现了滑动窗口机制。 Load 在Look-aside模型中，当数据不再Memcache中时，会向数据库读取数据，在这种情况下，会出现很多情况，从而导致负载加重。Memcache使用下列方法减少负载。 第一，Memcache使用Lease处理两个问题：Stale Set和Thundering Herd。Stale Set指的是服务器在Memcache中设置了过期的数据，这个数据不能反映最新的值。Thundering Herd指的是某个值在一段时间内被大量地读和写，如果Memcache中存的数据不是最新的，读和写就要去请求数据库，这导致数据库的负载大幅增加。 为了解决Stale Set问题，在Cache 未命中的时候，Memcache会给客户端分配一个64位的Lease， 当拿到数据库数据之后，需要使用这个Lease来证明其身份。如果这个数据在返回之前被Delete或者更改了，也就是说，现在的数据是更新的，那么这个Lease就会被认为是无效的，从而拒绝旧的写入。 为了解决Thunder Herd问题，Memcache会每10秒钟给这大量请求中的一个请求分配Lease，其他的客户端则被要求等待。这个持有Lease的请求会继续其流程，访问数据库，更新Memcache中的数据。而当Memcache中的数据被更新后，其他客户端会重新发起请求，这时大多数就能拿到其想要的数据了。那么，在整个流程中，重复的查询和写入被减少为一次。论文中表示，Lease的引入将数据库的查询次数从17K/S降低到了1.3K/S。 第二，Memcache使用了Memcache Pool来分别处理不同场景的数据。论文中举了例子说，可以为经常访问但处理Cache未命中的开销不大的Key提供一个小的Pool 。可以为不经常访问的Key提供一个大型Pool ，因为对于这些Key来说，Cache未命中的代价很高。 另外，论文还讨论了应该使用分片还是复制降低负载。考虑系统总共每秒1M个请求，一次客户端发起的请求包含100个key。如果是使用分片的话，假设对应的数据平均分配在在两台机器上，100个Key的请求，每台机器存储的恰好是50个Key，那么两台每秒仍然要处理1M个请求，只是每个请求拿的key少了，这是存储问题，但是不能解决 QPS 过高。使用复制的话，那么每台机器就只需要处理0.5M个请求了。所以，Memcache最后使用复制实习均衡负载。 Handle Failure 在缓存系统中，我们仍然要考虑容错的问题。因为Memcache是缓存系统，所以不影响数据库本身的正确性，那么我们就无需考虑一致性的问题，只需要考虑均衡负载，把本应分配给崩溃机器的请求分配给其他机器。 Memcache将崩溃分为两种情况，很少一部分机器崩溃，很大一部分机器崩溃。 很少一部分机器崩溃的解决依赖自动修复系统，Memcache准备了约占总机器数1%的机器来接管崩溃机器的服务，这些备用机器被称为Gutter。一旦客户端发现请求没有回应，它们就认为该机器崩溃，然后将请求转发到Gutter服务区上。 很大一部分机器崩溃的话，Memcache会考虑将这个Cluster的请求转发到其他Cluster上，以保证服务能正常提供。 In Region 在这部分中，Memcache讨论了在同一Region中的一些问题。 Regional Invalidations 考虑一下，某个客户端的写入请求会使存储集群的数据发生变化，但是这里的变化没有经过其他Memcache或者其他客户端，所以Memcache中的缓存实际是过时的，但是其他客户端和其他Memcache都不能意识到这一点，所以必须由数据存储集群来处理这个问题。 Memcache通过设置守护程序McSqueal来解决这个问题。当更新内容被Commit后，其会被送入到McSqueal中，McSqueal会判断这条语句是否会影响数据一致性。如果发现可能影响一致性的操作，它会将相关的信息送入Mcrouter中，再由Mcrouter发送给Memcache，这样Memcache就能根据相关的信息更新本地的数据，以此实现数据的一致性。在这里，McSqueal还使用批处理来降低系统的负载。其示意图如下。"
}
    </script>

    <!-- <script type="text/javascript" src="https://demo.ghost.io/public/ghost-sdk.min.js?v=724281a32e"></script>
    <script type="text/javascript">
    ghost.init({
    	clientId: "ghost-frontend",
    	clientSecret: "f84a07a72b17"
    });
    </script> -->

    <meta name="generator" content="Jekyll 3.6.2" />
    <link rel="alternate" type="application/rss+xml" title="浅谈Memcache" href="/feed.xml" />


</head>
<body class="post-template">

    <div class="site-wrapper">
        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- default -->

<!-- The tag above means: insert everything in this file
into the {body} of the default.hbs template -->

<header class="site-header outer">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left">
        
            
                <a class="site-nav-logo" href="http://localhost:4000/"><img src="/assets/images/blog-icon.png" alt="Ghost" /></a>
            
        
        
            <ul class="nav" role="menu">
    <li class="nav-home" role="menuitem"><a href="/">Home</a></li>
    <li class="nav-about" role="menuitem"><a href="/about/">About</a></li>
    <li class="nav-getting-started" role="menuitem"><a href="/tag/essay/">Essay</a></li>
    <li class="nav-home" role="menuitem"><a href="/tag/distributedsystem/">Distributed System</a></li>
</ul>

        
    </div>
    <div class="site-nav-right">
        <div class="social-links">
            
                <a class="social-link social-link-fb" href="https://facebook.com/ghost" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>
</a>
            
            
                <a class="social-link social-link-tw" href="https://twitter.com/tryghost" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>
</a>
            
        </div>
        
            <a class="subscribe-button" href="#subscribe">Subscribe</a>
        
    </div>
</nav>

    </div>
</header>

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<main id="site-main" class="site-main outer" role="main">
    <div class="inner">

        <article class="post-full  tag-distributedsystem post ">

            <header class="post-full-header">
                <section class="post-full-meta">
                    <time class="post-full-meta-date" datetime="24 August 2020">24 August 2020</time>
                    
                        <span class="date-divider">/</span>
                        
                            
                               <a href='/tag/distributedsystem/'>DISTRIBUTEDSYSTEM</a>
                            
                        
                    
                </section>
                <h1 class="post-full-title">浅谈Memcache</h1>
            </header>

            
            <figure class="post-full-image" style="background-image: url(/assets/images/memcache.jpg)">
            </figure>
            

            <section class="post-full-content">
                <div class="kg-card-markdown">
                    <p>上图为Facebook登录页面图片</p>

<p>Facebook拥有庞大的社交网络和因此产生的频繁的请求，所以为了提高响应速度，使用了缓存的策略处理这一问题。通常情况下，用户的读写请求都会落到数据库上，而数据库的数据存储在磁盘上，磁盘低下的读写效率对响应的速度影响很大。所以，Facebook使用运行在内存中的Memcached作为中间件，先在其中查询相关数据，只有当Memcached中没有请求的数据时才向数据库查询。他们充分利用了内存远高于磁盘的读写速度，实现了业务的优化。下面，我会根据其论文谈谈他们具体是怎么做的。要特别指出的是，Memcache指的的整个系统，而Memcached则是服务器中的组件，众多Memcached服务器组成了Memcache系统，两者是不同的。</p>

<h2 id="总体架构">总体架构</h2>

<p>Memcache的总体架构如下图所示</p>

<p><img src="/assets/images/Memcache Architecture.png" alt="Memcache Architecture" /></p>

<p>类似于Aurora和Spanner，Facebook也有Region的概念。现在，我们可以基本确定，Region指的是物理上实现地理分割的不同数据中心，这样划分可以根据用户的地理位置选择最近的数据中心来减少延迟。不同的Region之间只同步存储的数据。每个Region中有多个Cluster（集群），每个Cluster中又有多个Web服务器和Memcache系统，但每个Region只有唯一的存储集群。在这里，我想每个Cluster负责的业务应该是不同的，而每个Cluster中的多个服务器则应该是被用于实现均衡负载。</p>

<p>另外要讲的是Memcache的读写模型。Memcache使用的是Look-aside策略：服务器先尝试向Memcache读取数据，如果没有数据，则服务器再向数据库读取数据，读取完毕后将Memcache中的数据更新。示意图如下：</p>

<p><img src="/assets/images/Look-aside.png" alt="Look-aside" /></p>

<p>与之对应的是Inline策略，服务器尝试向Cache读取数据失败后，由Cache而不是服务器去数据库读取数据，再从Cache返回数据给服务器。</p>

<p>两者的区别在于处理数据缺失时的压力是由服务器还是缓存来承担。</p>

<p>下面，Memcache根据Cluster和Region分别讨论起内部的要求和优化。特别要说的是，在Facebook的应用场景中，读请求远比写请求多。</p>

<h2 id="in-cluster">In Cluster</h2>

<p>在Cluster中，Memcache主要关注两点，一是延迟（Latency），二是负载（Load）。</p>

<h3 id="latency">Latency</h3>

<p>在Facebook的服务中，一次get请求不仅仅只读取单个K-V对，根据统计，一次页面的加载平均要从Memcache读取521个不同的数据，所以必须要采取一些措施来降低读取数据的延迟。</p>

<p>第一，Memcache使用DAG来表示数据直接的依赖关系。如果有两组完全不相关的数据，那么这两组数据就可以并行地读取，而单个DAG中的数据可以一次性提交读请求而不是每个数据提交一次。这里使用的并行和批读取数据有效地提升了读取速度。</p>

<p>第二，Memcache使用UDP来发送读请求，TPC处理Set和Delete请求。由于UDP只负责发送而不考虑可靠性，也不维护链接，所以UDP要比TCP快。在大多数为读请求的情况下，使用UDP而不是TCP能减少读取的时间。而Set和Delete请求则要求必须可达，所以使用TCP。下图展示了UDP和TCP的性能比较。</p>

<p><img src="/assets/images/Memcache Udp.png" alt="Memcache Udp" /></p>

<p>第三，Memcache自己实现了一个类似TCP的拥塞窗口控制的机制以防止出现热点或阻塞。因为使用UDP传输读请求，所以自然也就没有TCP的拥塞窗口控制了。那么一旦出现大量的请求，UDP可能会使请求阻塞或者直接抛弃请求，抛弃请求则会使客户端重新发起请求，这两者都会影响整体的响应时间。所以Memcache在上层又实现了滑动窗口机制。</p>

<h3 id="load">Load</h3>

<p>在Look-aside模型中，当数据不再Memcache中时，会向数据库读取数据，在这种情况下，会出现很多情况，从而导致负载加重。Memcache使用下列方法减少负载。</p>

<p>第一，Memcache使用Lease处理两个问题：Stale Set和Thundering Herd。Stale Set指的是服务器在Memcache中设置了过期的数据，这个数据不能反映最新的值。Thundering Herd指的是某个值在一段时间内被大量地读和写，如果Memcache中存的数据不是最新的，读和写就要去请求数据库，这导致数据库的负载大幅增加。</p>

<p>为了解决Stale Set问题，在Cache 未命中的时候，Memcache会给客户端分配一个64位的Lease， 当拿到数据库数据之后，需要使用这个Lease来证明其身份。如果这个数据在返回之前被Delete或者更改了，也就是说，现在的数据是更新的，那么这个Lease就会被认为是无效的，从而拒绝旧的写入。</p>

<p>为了解决Thunder Herd问题，Memcache会每10秒钟给这大量请求中的一个请求分配Lease，其他的客户端则被要求等待。这个持有Lease的请求会继续其流程，访问数据库，更新Memcache中的数据。而当Memcache中的数据被更新后，其他客户端会重新发起请求，这时大多数就能拿到其想要的数据了。那么，在整个流程中，重复的查询和写入被减少为一次。论文中表示，Lease的引入将数据库的查询次数从17K/S降低到了1.3K/S。</p>

<p>第二，Memcache使用了Memcache Pool来分别处理不同场景的数据。论文中举了例子说，可以为经常访问但处理Cache未命中的开销不大的Key提供一个小的Pool 。可以为不经常访问的Key提供一个大型Pool ，因为对于这些Key来说，Cache未命中的代价很高。</p>

<p>另外，论文还讨论了应该使用分片还是复制降低负载。考虑系统总共每秒1M个请求，一次客户端发起的请求包含100个key。如果是使用分片的话，假设对应的数据平均分配在在两台机器上，100个Key的请求，每台机器存储的恰好是50个Key，那么两台每秒仍然要处理1M个请求，只是每个请求拿的key少了，这是存储问题，但是不能解决 QPS 过高。使用复制的话，那么每台机器就只需要处理0.5M个请求了。所以，Memcache最后使用复制实习均衡负载。</p>

<h3 id="handle-failure">Handle Failure</h3>

<p>在缓存系统中，我们仍然要考虑容错的问题。因为Memcache是缓存系统，所以不影响数据库本身的正确性，那么我们就无需考虑一致性的问题，只需要考虑均衡负载，把本应分配给崩溃机器的请求分配给其他机器。</p>

<p>Memcache将崩溃分为两种情况，很少一部分机器崩溃，很大一部分机器崩溃。</p>

<p>很少一部分机器崩溃的解决依赖自动修复系统，Memcache准备了约占总机器数1%的机器来接管崩溃机器的服务，这些备用机器被称为Gutter。一旦客户端发现请求没有回应，它们就认为该机器崩溃，然后将请求转发到Gutter服务区上。</p>

<p>很大一部分机器崩溃的话，Memcache会考虑将这个Cluster的请求转发到其他Cluster上，以保证服务能正常提供。</p>

<h2 id="in-region">In Region</h2>

<p>在这部分中，Memcache讨论了在同一Region中的一些问题。</p>

<h3 id="regional-invalidations">Regional Invalidations</h3>

<p>考虑一下，某个客户端的写入请求会使存储集群的数据发生变化，但是这里的变化没有经过其他Memcache或者其他客户端，所以Memcache中的缓存实际是过时的，但是其他客户端和其他Memcache都不能意识到这一点，所以必须由数据存储集群来处理这个问题。</p>

<p>Memcache通过设置守护程序McSqueal来解决这个问题。当更新内容被Commit后，其会被送入到McSqueal中，McSqueal会判断这条语句是否会影响数据一致性。如果发现可能影响一致性的操作，它会将相关的信息送入Mcrouter中，再由Mcrouter发送给Memcache，这样Memcache就能根据相关的信息更新本地的数据，以此实现数据的一致性。在这里，McSqueal还使用批处理来降低系统的负载。其示意图如下。</p>

<p><img src="/assets/images/Memcache Invalid SQL.png" alt="Memcache Invalid SQL" /></p>

<h3 id="region-pool">Region Pool</h3>

<p>由于每一个前端集群是独立处理发送过来的请求的，如果用户的请求被随机分配到每个集群，那么每个集群缓存的数据是差不多的。如果每个集群都保存一份相同的数据，那么有点得不偿失。所以Memcache设置一个Region Pool，即多个前端机器共享相同的Memcache集群。这样既能保证请求被响应，也能减少存储空间。</p>

<h3 id="warm-up">Warm Up</h3>

<p>在一个新的Memcache集群上线时，整个集群是没有数据的，那么所有转发过来的请求都会未命中。这时候如果这些请求全部去查询数据库，那么数据库的压力会很大。所以冷集群要热身，它会先去其它正常运行的集群去做查询用户需要的数据，如果命中了就不用去数据库查了。这大大减少了数据库的压力。</p>

<h2 id="across-region">Across Region</h2>

<p>由于Facebook有多个Region，而且每个Region的存储集群都是独立的，所以要保证数据的一致性还要额外的操作。由于读请求不会影响数据一致性，这里考虑两种情况，一是主Region写，二是从Region写。</p>

<p>处理主Region写要简单一些，当主Region接受写请求后，它会将命令写入数据库，然后广播给其他Region。从Region接受到广播的信息后就利用我们之前提到的McSqueal来同步本地存储和Memcache之间的数据。</p>

<p>处理从Region写则要麻烦一点，因为从Region必须保证和主Region一致而不能单独处理请求，一旦从Region在本地执行请求而主Region不处理，就会出现数据不一致的情况。这里，Memcache牺牲了一点效率，它会把从Region收到的写请求打上标记然后转发给主Region。只有当主Region处理完该请求并发回到从Region时，才会清除这个标记，那么此时，数据也就一致了。</p>

<h2 id="总结">总结</h2>

<p>Memcache最关键的一点在于它使用内存作为服务器和数据库之间的缓存，大大提高了数据访问的速度。在现在的系统设计中，Redis或者Memcache都是必不可少的一部分。另外，它在优化延迟和负载时使用的解决方案也相当有趣，虽然看起来很简单，但从数据上来看相当使用。但是，从我个人角度来看，他在实现缓存一致性的问题上解决方案不是很高效。想要在Memcache中实现跨Region之间或者跨Cluster之间的缓存数据一致性，那么必须要经过数据库，还要使用McSqueal和Mcrouter调整，效率想必是很低下的。不知道这后来有没有更好的解决方案。</p>

                </div>
            </section>


            <footer class="post-full-footer">
                <!-- Everything inside the #author tags pulls data from the author -->
                <!-- #author-->
                
                    
                        <section class="author-card">
                            
                                <img class="author-profile-image" src="/assets/images/trl.png" alt="TrafalgarRicardoLu" />
                            
                            <section class="author-card-content">
                                <h4 class="author-card-name"><a href="/author/TrafalgarRicardoLu">Trafalgar Ricardo Lu</a></h4>
                                
                                    <p>Stay foolish,stay sated.</p>
                                
                            </section>
                        </section>
                        <div class="post-full-footer-right">
                            <a class="author-card-button" href="/author/TrafalgarRicardoLu">Read More</a>
                        </div>
                    
                
                <!-- /author  -->
            </footer>

            <!-- If you use Disqus comments, just uncomment this block.
            The only thing you need to change is "test-apkdzgmqhj" - which
            should be replaced with your own Disqus site-id. -->
            

        </article>

    </div>
</main>

<!-- Links to Previous/Next posts -->
<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
                
                
                
                
                    <article class="read-next-card"
                        
                            style="background-image: url(/assets/images/blog-cover.jpg)"
                        
                    >
                        <header class="read-next-card-header">
                            <small class="read-next-card-header-sitetitle">&mdash; Ghost &mdash;</small>
                            
                                <h3 class="read-next-card-header-title"><a href="/tag/distributedsystem/">Distributedsystem</a></h3>
                            
                        </header>
                        <div class="read-next-divider"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/></svg>
</div>
                        <div class="read-next-card-content">
                            <ul>
                                
                                
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/Paxos%E7%AE%97%E6%B3%95%E7%9A%84%E5%8F%91%E5%B1%95">共识性算法的发展</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/%E5%9B%9E%E9%A1%BEMIT6.824">回顾MIT 6.824</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/%E6%B5%85%E8%B0%88Spanner">浅谈Spanner</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                            </ul>
                        </div>
                        <footer class="read-next-card-footer">
                            <a href="/tag/distributedsystem/">
                                
                                    See all 11 posts  →
                                
                            </a>
                        </footer>
                    </article>
                
            

            <!-- If there's a next post, display it using the same markup included from - partials/post-card.hbs -->
            
                

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/%E5%9B%9E%E9%A1%BEMIT6.824">
                <div class="post-card-image" style="background-image: url(/assets/images/MIT6.824.png)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/%E5%9B%9E%E9%A1%BEMIT6.824">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Distributedsystem</span>
                            
                        
                    

                    <h2 class="post-card-title">回顾MIT 6.824</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p></p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                        
                        <img class="author-profile-image" src="/assets/images/trl.png" alt="Trafalgar Ricardo Lu" />
                        
                        <span class="post-card-author">
                            <a href="/author/TrafalgarRicardoLu/">Trafalgar Ricardo Lu</a>
                        </span>
                    
                
                <span class="reading-time">
                    
                    
                      1 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

            <!-- If there's a previous post, display it using the same markup included from - partials/post-card.hbs -->
            
                

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/%E6%B5%85%E8%B0%88Spanner">
                <div class="post-card-image" style="background-image: url(/assets/images/spanner.jpeg)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/%E6%B5%85%E8%B0%88Spanner">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Distributedsystem</span>
                            
                        
                    

                    <h2 class="post-card-title">浅谈Spanner</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p></p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                        
                        <img class="author-profile-image" src="/assets/images/trl.png" alt="Trafalgar Ricardo Lu" />
                        
                        <span class="post-card-author">
                            <a href="/author/TrafalgarRicardoLu/">Trafalgar Ricardo Lu</a>
                        </span>
                    
                
                <span class="reading-time">
                    
                    
                      1 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

        </div>
    </div>
</aside>

<!-- Floating header which appears on-scroll, included from includes/floating-header.hbs -->
<div class="floating-header">
    <div class="floating-header-logo">
        <a href="http://localhost:4000/">
            
                <img src="/assets/images/favicon.png" alt="Ghost icon" />
            
            <span>Ghost</span>
        </a>
    </div>
    <span class="floating-header-divider">&mdash;</span>
    <div class="floating-header-title">浅谈Memcache</div>
    <div class="floating-header-share">
        <div class="floating-header-share-label">Share this <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M7.5 15.5V4a1.5 1.5 0 1 1 3 0v4.5h2a1 1 0 0 1 1 1h2a1 1 0 0 1 1 1H18a1.5 1.5 0 0 1 1.5 1.5v3.099c0 .929-.13 1.854-.385 2.748L17.5 23.5h-9c-1.5-2-5.417-8.673-5.417-8.673a1.2 1.2 0 0 1 1.76-1.605L7.5 15.5zm6-6v2m-3-3.5v3.5m6-1v2"/>
</svg>
</div>
        <a class="floating-header-share-tw" href="https://twitter.com/share?text=%E6%B5%85%E8%B0%88Memcache&amp;url=https://jekyller.github.io/jasper2/%E6%B5%85%E8%B0%88Memcache"
            onclick="window.open(this.href, 'share-twitter', 'width=550,height=235');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

        </a>
        <a class="floating-header-share-fb" href="https://www.facebook.com/sharer/sharer.php?u=https://jekyller.github.io/jasper2/%E6%B5%85%E8%B0%88Memcache"
            onclick="window.open(this.href, 'share-facebook','width=580,height=296');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

        </a>
    </div>
    <progress class="progress" value="0">
        <div class="progress-container">
            <span class="progress-bar"></span>
        </div>
    </progress>
</div>


<!-- /post -->

<!-- The #contentFor helper here will send everything inside it up to the matching #block helper found in default.hbs -->


        <!-- Previous/next page links - displayed on every page -->
        

        <!-- The footer at the very bottom of the screen -->
        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="http://localhost:4000/">Ghost</a> &copy; 2021</section>
                <section class="poweredby">Proudly published with <a href="https://jekyllrb.com/">Jekyll</a> &
                    <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> using
                    <a href="https://github.com/jekyller/jasper2" target="_blank" rel="noopener">Jasper2</a></section>
                <nav class="site-footer-nav">
                    <a href="/">Latest Posts</a>
                    <a href="https://facebook.com/ghost" target="_blank" rel="noopener">Facebook</a>
                    <a href="https://twitter.com/tryghost" target="_blank" rel="noopener">Twitter</a>
                    <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a>
                </nav>
            </div>
        </footer>

    </div>

    <!-- The big email subscribe modal content -->
    
        <div id="subscribe" class="subscribe-overlay">
            <a class="subscribe-overlay-close" href="#"></a>
            <div class="subscribe-overlay-content">
                
                    <img class="subscribe-overlay-logo" src="/assets/images/blog-icon.png" alt="Ghost" />
                
                <h1 class="subscribe-overlay-title">Subscribe to Ghost</h1>
                <p class="subscribe-overlay-description">Stay up to date! Get all the latest &amp; greatest posts delivered straight to your inbox</p>
                <form method="post" action="/subscribe/" class="">
    <input class="confirm" type="hidden" name="confirm"  /><input class="location" type="hidden" name="location"  /><input class="referrer" type="hidden" name="referrer"  />

    <div class="form-group">
        <input class="subscribe-email" type="email" name="email"  placeholder="youremail@example.com" />
    </div>
    <button class="" type="submit" disabled><span>Subscribe</span></button>
    <script type="text/javascript">(function(g,h,o,s,t){h[o]('.location')[s]=h[o]('.location')[s] || g.location.href;h[o]('.referrer')[s]=h[o]('.referrer')[s] || h.referrer;})(window,document,'querySelector','value');</script>
</form>

            </div>
        </div>
    

    <!-- highlight.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script>
    <script>$(document).ready(function() {
      $('pre code').each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });</script>

    <!-- jQuery + Fitvids, which makes all video embeds responsive -->
    <script
        src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="https://demo.ghost.io/assets/js/jquery.fitvids.js?v=724281a32e"></script>


    <!-- Paginator increased to "infinit" in _config.yml -->
    <!-- if paginator.posts  -->
    <!-- <script>
        var maxPages = parseInt('');
    </script>
    <script src="/assets/js/infinitescroll.js"></script> -->
    <!-- /endif -->

    


    <!-- Add Google Analytics  -->
    <!-- Google Analytics Tracking code -->
 <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-69281367-1', 'auto');
  ga('send', 'pageview');

 </script>


    <!-- The #block helper will pull in data from the #contentFor other template files. In this case, there's some JavaScript which we only want to use in post.hbs, but it needs to be included down here, after jQuery has already loaded. -->
    
        <script>

// NOTE: Scroll performance is poor in Safari
// - this appears to be due to the events firing much more slowly in Safari.
//   Dropping the scroll event and using only a raf loop results in smoother
//   scrolling but continuous processing even when not scrolling
$(document).ready(function () {
    // Start fitVids
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
    // End fitVids

    var progressBar = document.querySelector('progress');
    var header = document.querySelector('.floating-header');
    var title = document.querySelector('.post-full-title');

    var lastScrollY = window.scrollY;
    var lastWindowHeight = window.innerHeight;
    var lastDocumentHeight = $(document).height();
    var ticking = false;

    function onScroll() {
        lastScrollY = window.scrollY;
        requestTick();
    }

    function onResize() {
        lastWindowHeight = window.innerHeight;
        lastDocumentHeight = $(document).height();
        requestTick();
    }

    function requestTick() {
        if (!ticking) {
            requestAnimationFrame(update);
        }
        ticking = true;
    }

    function update() {
        var trigger = title.getBoundingClientRect().top + window.scrollY;
        var triggerOffset = title.offsetHeight + 35;
        var progressMax = lastDocumentHeight - lastWindowHeight;

        // show/hide floating header
        if (lastScrollY >= trigger + triggerOffset) {
            header.classList.add('floating-active');
        } else {
            header.classList.remove('floating-active');
        }

        progressBar.setAttribute('max', progressMax);
        progressBar.setAttribute('value', lastScrollY);

        ticking = false;
    }

    window.addEventListener('scroll', onScroll, {passive: true});
    window.addEventListener('resize', onResize, false);

    update();
});
</script>

    

    <!-- Ghost outputs important scripts and data with this tag - it should always be the very last thing before the closing body tag -->
    <!-- ghost_foot -->

</body>
</html>
